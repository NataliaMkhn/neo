Описание проектной работы

ссылка на репозиторий:
https://gitlab.skillbox.ru/natalia_mokhnacheva/neoflex.git



ссылки на видео в яндекс-диске:
https://disk.yandex.ru/i/1TbrD3nUrtEAvA  - демонстрация создания таблиц, запуска всего потока, просмотр таблицы логов.

https://disk.yandex.ru/i/6H_zptw8gYQzWg - видео к задаче 1.1. (Продемонстрируйте как вы в файле «ft_balance_f.csv» 
меняете баланс для какого-нибудь <account_rk>, показываете что в таблице «DS.ft_balance_f» сперва была одна сумма 
у этого <account_rk> - потом запускаете ETL-процесс и показываете, что в таблице сумма обновилась)

https://disk.yandex.ru/i/_CjpAUdqGRaJIg - видео к задаче 1.2. (Нужно продемонстрировать, как вы запускаете расчёт 
ежедневной витрины оборотов и витрины остатков за весь месяц и то как в витринах постепенно начинают появляться 
данные за разные дни Января)

https://disk.yandex.ru/i/w_0qcW1Mz8xqZg - видео к задаче 1.3. (Покажите, как вы разработали процедуру расчёта 
101-й формы и то как вы запускаете её расчёт и данные появляются в витрине)

https://disk.yandex.ru/i/-0Xe5eQc19SLuA - видео к задаче 1.4. (напишите скрипт, который позволит импортировать 
их обратно в БД. Поменяйте пару значений в выгруженном csv-файле и загрузите его в копию таблицы 
101-формы «dm. dm _f101_round_f_v2»)

Скрипты:
create dwh_db.sql - создание БД dwh_db (только БД. схемы и таблицы создаются отдельно).

1_1 create_table.sql - скрипт создания схем и таблиц в базе данных.
1_1 insert_data (pandas).sql - скрипт обработки данных после загрузки - приведение к нужным типам данных, удаление дубликатов).
1_2 fill_balance_turnover.sql - скрипт создания процедуры расчета витрины оборотов и процедуры расчета витрины остатков за определенную дату.
1_2 fill_month.sql - скрипт расчета всех витрин за один полный месяц. 
1_3 fill_101.sql - скрипт расчета формы 101 за один месяц.



de (pandas).py  - запуск потока (заполнение данных и расчет всех витрин) из airflow.
101_from_csv.py - запуск потока загрузки копии таблицы 101 из csv файла. airflow.



Дополнительно к проектной работе:
папка dop 1:
de_(spark).py - вариант запуска потока из airflow с использованием pyspark.
1_1 insert_data (spark).sql - скрипт обработки данных после загрузки в случае, если для запуска потока был использован de_(spark).py

